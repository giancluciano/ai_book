{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e70dd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"my_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4599a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '3-cartpole.ipynb'}, page_content='\\'markdown\\' cell: \\'[\\'# cartpole\\']\\'\\n\\n\\'code\\' cell: \\'[\\'import matplotlib.pyplot as plt\\\\n\\', \\'import gymnasium as gym\\\\n\\', \\'from IPython import display\\\\n\\', \\'%matplotlib inline\\\\n\\', \\'\\\\n\\']\\'\\n\\n\\'code\\' cell: \\'[\\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[\\'\\\\n\\', \\'## ploting on jupyter\\\\n\\', \\'plt.figure(figsize=(2, 1))\\\\n\\', \\'for i in range(25):\\\\n\\', \\'   plt.imshow(env.render())\\\\n\\', \\'   display.display(plt.gcf())\\\\n\\', \\'   display.clear_output(wait=True)\\\\n\\', \\'   env.step(env.action_space.sample()) # take a random action\\\\n\\', \\'\\\\n\\', \\'env.close()\\\\n\\']\\'\\n\\n\\'code\\' cell: \\'[\\'import numpy as np\\\\n\\', \\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'q = np.zeros((env.observation_space.n, env.action_space.n))\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'learning_rate_a = 0.9\\\\n\\', \\'discount_factor_g = 0.9\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[]\\'\\n\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import NotebookLoader\n",
    "\n",
    "\n",
    "\n",
    "documents = NotebookLoader(\"3-cartpole.ipynb\").load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c60447a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '3-cartpole.ipynb'}, page_content='\\'markdown\\' cell: \\'[\\'# cartpole\\']\\'\\n\\n\\'code\\' cell: \\'[\\'import matplotlib.pyplot as plt\\\\n\\', \\'import gymnasium as gym\\\\n\\', \\'from IPython import display\\\\n\\', \\'%matplotlib inline\\\\n\\', \\'\\\\n\\']\\'\\n\\n\\'code\\' cell: \\'[\\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[\\'\\\\n\\', \\'## ploting on jupyter\\\\n\\', \\'plt.figure(figsize=(2, 1))\\\\n\\', \\'for i in range(25):\\\\n\\', \\'   plt.imshow(env.render())\\\\n\\', \\'   display.display(plt.gcf())\\\\n\\', \\'   display.clear_output(wait=True)\\\\n\\', \\'   env.step(env.action_space.sample()) # take a random action\\\\n\\', \\'\\\\n\\', \\'env.close()\\\\n\\']\\''),\n",
       " Document(metadata={'source': '3-cartpole.ipynb'}, page_content='\\'code\\' cell: \\'[\\'import numpy as np\\\\n\\', \\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'q = np.zeros((env.observation_space.n, env.action_space.n))\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'learning_rate_a = 0.9\\\\n\\', \\'discount_factor_g = 0.9\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[]\\'')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_text_splitters import PythonCodeTextSplitter\n",
    "\n",
    "text_splitter = PythonCodeTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e283b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\'markdown\\' cell: \\'[\\'# cartpole\\']\\'\\n\\n\\'code\\' cell: \\'[\\'import matplotlib.pyplot as plt\\\\n\\', \\'import gymnasium as gym\\\\n\\', \\'from IPython import display\\\\n\\', \\'%matplotlib inline\\\\n\\', \\'\\\\n\\']\\'\\n\\n\\'code\\' cell: \\'[\\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[\\'\\\\n\\', \\'## ploting on jupyter\\\\n\\', \\'plt.figure(figsize=(2, 1))\\\\n\\', \\'for i in range(25):\\\\n\\', \\'   plt.imshow(env.render())\\\\n\\', \\'   display.display(plt.gcf())\\\\n\\', \\'   display.clear_output(wait=True)\\\\n\\', \\'   env.step(env.action_space.sample()) # take a random action\\\\n\\', \\'\\\\n\\', \\'env.close()\\\\n\\']\\'',\n",
       " '\\'code\\' cell: \\'[\\'import numpy as np\\\\n\\', \\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'q = np.zeros((env.observation_space.n, env.action_space.n))\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'learning_rate_a = 0.9\\\\n\\', \\'discount_factor_g = 0.9\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[]\\'']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    documents.append(chunk.page_content)\n",
    "    metadata.append(chunk.metadata)\n",
    "    ids.append(f\"chunk_{i}\")\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac8aca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.upsert(\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids\n",
    ")\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6224841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# =============================================================================\n",
    "# SETUP AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Ollama typically runs on localhost:11434\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_API_URL = f\"{OLLAMA_BASE_URL}/v1\"\n",
    "\n",
    "# Configure OpenAI client to use Ollama\n",
    "openai_client = openai.OpenAI(\n",
    "    base_url=OLLAMA_API_URL,\n",
    "    api_key=\"ollama\"  # Ollama doesn't require a real API key, but OpenAI client expects one\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant. You answer questions about the Python script provided.\n",
    "but you only answer based on the content of the script. You don't use any prior knowledge and you don't make up answers.\n",
    "If you don't know the answer, just say \"I don't know\".\n",
    "\n",
    "the data:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "609ab59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['chunk_1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['\\'code\\' cell: \\'[\\'import numpy as np\\\\n\\', \\'env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\\\\n\\', \\'observation, info = env.reset()\\\\n\\', \\'\\\\n\\', \\'q = np.zeros((env.observation_space.n, env.action_space.n))\\\\n\\', \\'\\\\n\\', \\'terminated = False\\\\n\\', \\'truncated = False\\\\n\\', \\'\\\\n\\', \\'learning_rate_a = 0.9\\\\n\\', \\'discount_factor_g = 0.9\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'while not terminated and not truncated:\\\\n\\', \\'    new_state, reward, terminated, truncated, _ = env.step(env.action_space.sample())\\\\n\\', \\'    observation = new_state\\\\n\\', \\'\\\\n\\', \\'env.close()\\']\\'\\n\\n\\'code\\' cell: \\'[]\\'']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': '3-cartpole.ipynb'}]],\n",
       " 'distances': [[1.2238738536834717]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"is the reward variable being used in the code?\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[user_query],\n",
    "    n_results=1\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c3b1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The `reward` variable is not explicitly used in the provided code. It seems that it's being stored as part of the new state (`new_state`) for later use, but its value isn't being utilized anywhere within the loop.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt + str(results['documents'])},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965d75b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we read `3-cartpole.ipynb` file and store it on chromadb Vector Database.\n",
    "The Vector database then divide the file on small chunks and allow us to seach and retrieve the most relevant chunck based on our query\n",
    "\n",
    "Later, we ask the question `\"is the reward variable being used in the code?\"` so we:\n",
    "1. search the vector database and retrieve the most relevant chunk \n",
    "2. create a custom system prompt adding instructions + the chunck data\n",
    "3. send to openai api the system prompt + the user question \n",
    "\n",
    "In conclusion, the agent give us a not 100% correct answer that \"The `reward` variable is not explicitly used in the provided code. It seems that it's being stored as part of the new state (`new_state`) for later use\"\n",
    "where the first part is correct but the `It seems that it's being stored as part of the new state (new_state) for later use` part is false.\n",
    "\n",
    "Here we are using a very small model running on local environment which may have caused the imprecise answer, also, I could improve the vector store parameters which I didn't paid much attention yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536abf63",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
