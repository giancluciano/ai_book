{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fccdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prioritized experience replay vs replay memory\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6e40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be429b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_memory = ReplayMemory(1000)\n",
    "r_memory.append(1)\n",
    "r_memory.append(2)\n",
    "r_memory.append(3)\n",
    "# Sample a single element from the replay memory\n",
    "r_memory.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "559d131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1, dtype=np.float32)\n",
    "        self.data_pointer = 0\n",
    "    \n",
    "    def update(self, idx, priority):\n",
    "        tree_index = idx + self.capacity - 1\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "        while tree_index != 0:\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "        \n",
    "    def get_leaf(self, idx):\n",
    "        parent_index = 0\n",
    "        print(self.tree)\n",
    "        while True:\n",
    "            print(f\"Searching for leaf: idx={idx}, parent_index={parent_index}\")\n",
    "            left_child = 2 * parent_index + 1\n",
    "            right_child = left_child + 1\n",
    "\n",
    "            if left_child >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "            if idx <= self.tree[left_child]:\n",
    "                parent_index = left_child\n",
    "            else:\n",
    "                idx -= self.tree[left_child]\n",
    "                parent_index = right_child\n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "        return data_index, self.tree[leaf_index]\n",
    "    \n",
    "    def total_sum(self):\n",
    "        return self.tree[0]\n",
    "    \n",
    "    def print_tree(self):\n",
    "        print(self.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ac592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 0. 1. 2. 0. 0.]\n",
      "Searching for leaf: idx=4, parent_index=0\n",
      "Searching for leaf: idx=1.0, parent_index=2\n",
      "Searching for leaf: idx=1.0, parent_index=6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, np.float32(0.0))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_tree = SumTree(4)\n",
    "sum_tree.update(0, 1)\n",
    "sum_tree.update(1, 2)\n",
    "\n",
    "sum_tree.get_leaf(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edec8f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(3.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_tree.total_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e131d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 0. 1. 2. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "sum_tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d53540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayMemory():\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        self.capacity = capacity\n",
    "        self.alpha = alpha  # alpha = 0.6 (controls how much prioritization is used) 0 = no prioritization, 1 = full prioritization\n",
    "        self.priorities = SumTree(capacity)\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        self.max_priority = 1.0\n",
    "        \n",
    "    def store(self, state, action, reward, next_state, done, priority):\n",
    "        experience = (state, action, reward, next_state, done)\n",
    "        \n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(experience)\n",
    "        else:\n",
    "            self.buffer[self.position] = experience\n",
    "        \n",
    "        self.priorities.update(self.position, priority ** self.alpha)\n",
    "        self.max_priority = max(self.max_priority, priority)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def update_priority(self, index, priority):\n",
    "        self.priorities.update(index, priority ** self.alpha)\n",
    "        self.max_priority = max(self.max_priority, priority)\n",
    "    \n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        indices = []\n",
    "        priorities = []\n",
    "        experiences = []\n",
    "\n",
    "        # sample based on priority\n",
    "        total_priority = self.priorities.total_sum()\n",
    "        segment_size = total_priority / batch_size\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a = segment_size * i\n",
    "            b = segment_size * (i + 1)\n",
    "            value = random.uniform(a, b)\n",
    "\n",
    "            index, priority = self.priorities.get_leaf(value)\n",
    "            indices.append(index)\n",
    "            priorities.append(priority)\n",
    "            experiences.append(self.buffer[index])\n",
    "\n",
    "        # calculate importance sampling weights\n",
    "        weights = []\n",
    "        min_prob = min(priorities) / total_priority\n",
    "        max_weight = (min_prob * len(self.buffer)) ** (-beta)\n",
    "\n",
    "        for priority in priorities:\n",
    "            prob = priority / total_priority\n",
    "            weight = (prob * len(self.buffer)) ** (-beta)\n",
    "            weights.append(weight / max_weight)\n",
    "        \n",
    "        return experiences, indices, weights\n",
    "\n",
    "    def get_max_priority(self):\n",
    "        return self.max_priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff420a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2511886  0.25118864 1.         0.25118864 0.        ]\n",
      "Searching for leaf: idx=0.9921334981918335, parent_index=0\n",
      "Searching for leaf: idx=0.7409448623657227, parent_index=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0, 2, 1, 1, True)], [0], [np.float32(1.0)])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm = PrioritizedReplayMemory(3)\n",
    "state = 0\n",
    "new_state = 1\n",
    "action = 2\n",
    "reward = 1\n",
    "done = True\n",
    "priority = 1.0\n",
    "prm.store(state, action, reward, new_state, done, priority)\n",
    "\n",
    "state = 1\n",
    "new_state = 2\n",
    "action = 2\n",
    "reward = 0\n",
    "done = False\n",
    "priority = 0.1\n",
    "prm.store(state, action, reward, new_state, done, priority)\n",
    "\n",
    "prm.sample(1, beta=0.4)  # will sample first element with priority 1.0 most of the time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b5ee1",
   "metadata": {},
   "source": [
    "## Why Alpha = 0.6 is Common\n",
    "This value was found empirically to provide a good balance:\n",
    "\n",
    "Strong enough to accelerate learning by focusing on important experiences\n",
    "Not too strong to completely ignore experiences with small TD-errors\n",
    "Maintains diversity in the training batch\n",
    "Proven effective across many different environments in the original PER paper\n",
    "\n",
    "### Trade-offs\n",
    "Higher Alpha (closer to 1.0):\n",
    "\n",
    "- ✅ Faster initial learning\n",
    "- ✅ Focus on most informative experiences\n",
    "- ❌ Risk of overfitting to high-error experiences\n",
    "- ❌ May ignore important but \"boring\" experiences\n",
    "\n",
    "Lower Alpha (closer to 0.0):\n",
    "\n",
    "- ✅ More diverse sampling\n",
    "- ✅ Less risk of overfitting\n",
    "- ❌ Slower learning\n",
    "- ❌ Less benefit from prioritization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c269d",
   "metadata": {},
   "source": [
    "## The Problem Beta Solves\n",
    "When we use prioritized sampling instead of uniform sampling, we introduce bias into our learning algorithm. Beta corrects this bias to maintain theoretical convergence guarantees.\n",
    "\n",
    "## What is Importance Sampling?\n",
    "Imagine you're trying to estimate the average height of people in a city, but your sampling method accidentally selects tall people more often. To get the correct average, you need to down-weight the tall people's contributions. That's importance sampling!\n",
    "\n",
    "\n",
    "### Beta Values and Their Effects\n",
    "#### Beta = 0 (No Bias Correction)\n",
    "- all samples get equal weight in loss calculation\n",
    "- Fastest learning but biased\n",
    "- Essentially ignores the sampling bias\n",
    "\n",
    "#### Beta = 1 (Full Bias Correction)\n",
    "- Fully corrects the sampling bias\n",
    "- Theoretically sound but slower learning\n",
    "- High-priority samples get heavily down-weighted\n",
    "\n",
    "#### Beta = 0.4 → 1.0 (Annealed)\n",
    "\n",
    "- Starts with fast, biased learning\n",
    "- Gradually becomes unbiased\n",
    "- Best of both worlds approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f201ca6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
